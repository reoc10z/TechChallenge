{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HEADLINE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4r7WAozsHm9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "#Data Science Technical Challenge - (Deadline: Sep 16 2024 11:59 p.m.) - Test, no es una prueba de ingreso\n",
        "\n",
        "## Take Home: Financial Transactions\n",
        "\n",
        "\n",
        "### Agosto 2024\n",
        "\n",
        "<hr style=\"height:2pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYw5R8X5sHm_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Descripción\n",
        "\n",
        "El siguiente dataset contiene 116.201 registros de transacciones financieras de dominio público, enriquecida con data sintentica.\n",
        "\n",
        "El objetivo de este ejercicio es realizar un Exploratory Data Analysis (EDA) de este dataset, para entender la información contenida y obtener insights relevantes para ciertas tareas analíticas.\n",
        "\n",
        "Se puede descargar el dataset (formato parquet) desde este [link](https://drive.google.com/file/d/1RjeIHmtOTxz4M9WVhh8n9YsMTjk-1V80/view?usp=drive_link). Tendrás acceso a este archivo hasta la fecha límite del challenge que se te indicará en el correo.\n",
        "\n",
        "A continuación, una descripción de las columnas:\n",
        "\n",
        "| Variable            | Descripción                                                                 |\n",
        "| :------------------ | :-------------------------------------------------------------------------- |\n",
        "| account_id          | Número de cuenta involucrado en la transacción.                              |\n",
        "| date                | Fecha de la transacción.                                                     |\n",
        "| transaction_details | Narración o descripción de la transacción en los estados de cuenta bancarios.|\n",
        "| chq_no              | Número de cheque asociado con la transacción, si corresponde.                |\n",
        "| value_date          | Fecha de finalización de la transacción.                                     |\n",
        "| withdrawal_amt.     | Monto retirado en la transacción.                                            |\n",
        "| deposit_amt         | Monto depositado en la transacción.                                          |\n",
        "| balance_amt         | Saldo actual de la cuenta después de la transacción.                         |\n",
        "| category            | Categoría asignada basada en los detalles de la transacción.       |\n",
        "| city                | Ciudad donde se asume que ocurrió la transacción.                  |\n",
        "| device              | Tipo de dispositivo utilizado para la transacción (e.g., Móvil, Escritorio, Tablet). |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTaJvdhLsHm_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Tareas\n",
        "\n",
        "En este notebook se deberá cargar todas las librerías que se necesitan para explorar y procesar el dataset dado, y así realizar el analisis corresponendiente para extraer insights sobre la información dada. Se puede realizar cualquier análisis deseado, pero al final se espera encontrar realizadas las tareas del tipo \"requerido\". Además, hay algunos aspectos valorados del tipo \"deseable\" y \"bonus\" para obtener una valoración sobresaliente en este ejercicio.\n",
        "\n",
        "El código debe ser desarrollado en Python >= 3.9. Los reportes pueden estar en español o inglés.\n",
        "\n",
        "### Requerido\n",
        "\n",
        "- **Data QA:** Se debe chequear la calidad del dataset para hacer una evaluación de qué tan apropiados son los datos para tareas de Data Science. Proponga un conjunto de correcciones en los datos de ser necesario.\n",
        "- **Reporting:** Documente los resultados e insights obtenidos durante la exploración y describa conclusiones desde una perspectiva de negocio, soportado por gráficos / tablas / métricas.\n",
        "- **Machine Learning:** Describa las posibles tareas de Machine Learning que podrían realizarse desde el dataset dado, que podrían ser valiosas en el dominio dado (sólo explicar, **no entrenar un modelo**).\n",
        "\n",
        "\n",
        "\n",
        "### Deseable\n",
        "\n",
        "- **Versionado de código con Git** (incluso puede publicarse en tu cuenta personal de GitHub!).\n",
        "- **Feature Engineering:** Indicar y calcular posibles candidatos de features que podrían utilizarse tanto columnas originales y transformaciones.\n",
        "- **Modelo predictivo:** Realice un modelo predictivo.\n",
        "- **Mostrar skills en Python:** Teniendo buenas practicas en la estructura del código y la documentación.\n",
        "- **Casos de uso:** Describir posibles casos de usos a tratar con este dataset que podrían agregar valor al negocio dado, indicando métodos / técnicas y algoritmos por cada uno de ellos, así como justificando las decisiones tomadas.\n",
        "- **Métricas:** Definir y calcular las métricas que considere más relevantes para la problemática propuesta.\n",
        "\n",
        "### Bonus\n",
        "\n",
        "- Manejo de environment de desarrollo mediante alguna tecnología (e.g. Docker, virtualenv, conda).\n",
        "- Identificar nuevos atributos / tablas que podrían ser relevantes o necesarias para un mejor análisis.\n",
        "\n",
        "Este ejercicio está diseñado para ser completado en ~3 hs siguiendo sólo los aspectos del tipo \"requerido\", pero se contempla una semana para entregarlo con todos los aspectos que se deseen completar.\n",
        "\n",
        "Una vez completado este ejercicio, por favor mandar un archivo ZIP de la\n",
        "carpeta con todos los recursos usados en este trabajo (e.g. Jupyter notebook,\n",
        " scripts, documentos, imágenes, etc), también puedes compartir un collab reproducible, o bien el enlace al repositorio de\n",
        " GitHub, a `jaison.gonzalez@mercadolibre.com.co`\n",
        "\n",
        "**Que te diviertas!**\n",
        "\n",
        "<img src=\"http://s3.amazonaws.com/melidata-external/data-science-interviews/2021/img/hunger_games_data_meme.jpeg\" alt=\"drawing\" style=\"width:200px;\"/>\n",
        "\n",
        "### Anotaciones\n",
        "\n",
        "- Está permitido usar las herramientas y librerias que consideres, solo ten presente que luego se te pedirá justificar.\n",
        "- Aseguraté de que tu trabajo sea reproducible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxRjTa6ql0m8"
      },
      "source": [
        "# SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "import logging\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_palette(\"pastel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Methods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pie(df:pd.DataFrame,column:str):\n",
        "    \"\"\"this plots a pie for the column specified\"\"\"\n",
        "    n_counts = df[column].value_counts()\n",
        "    labels = labels=n_counts.index\n",
        "    plt.pie(n_counts,labels=labels, autopct='%1.1f%%', startangle=140)\n",
        "    plt.title(f'Distribution of {column}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_pies(df:pd.DataFrame,col1:str,col2:str,len1:int=4,len2:int=4):\n",
        "    \"\"\"it plots two concentric pies. The outter circle will correspond to the columns col1. The inner circle will correspondond to the column col2.\n",
        "    The col2 will be groupped inside each group of the groups made by the col1 variable\n",
        "    @len1: number of characters to take from the names in col1\n",
        "    @lenw: number of characters to take from the names in col2\n",
        "    \"\"\"\n",
        "    df = df.sort_values(by=col1)    \n",
        "    df['agrupadas'] = df[col1].apply(lambda x: x.replace(\" \", \"\")).str[:len1] + '_' + df[col2].str[:len2]\n",
        "\n",
        "    # Make data:\n",
        "    group_names = list(df[col1].unique())  # Create group names (group1 to group10)\n",
        "    group_size = df[col1].value_counts().sort_index()  # Assuming all groups have equal size (adjust as needed)\n",
        "\n",
        "    subgroup_names = list(df['agrupadas'].unique())\n",
        "    subgroup_size = df['agrupadas'].value_counts().sort_index()\n",
        "\n",
        "    # Create colors:\n",
        "    num_groups = len(group_names)\n",
        "    color_map = plt.get_cmap('tab10')  # Use a colormap for 10 groups\n",
        "    colors = [color_map(i / num_groups) for i in range(num_groups)]\n",
        "\n",
        "    # First Ring (outside)\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.axis('equal')\n",
        "    mypie, wedges, _ = ax.pie(group_size, radius=2.5, labels=group_names, autopct=\"%1.1f%%\", pctdistance=0.9, colors=colors)\n",
        "    plt.setp(mypie, width=0.5, edgecolor='white')\n",
        "\n",
        "    # Second Ring (Inside)\n",
        "    mypie2, _ = ax.pie(subgroup_size, radius=2.5 - 0.5, labels=subgroup_names, labeldistance=0.7, colors=colors, textprops={'fontsize': 8}, rotatelabels=True)\n",
        "    plt.setp(mypie2, width=0.8, edgecolor='white')\n",
        "\n",
        "    # Add title and legend\n",
        "    plt.suptitle(f\"Distribution of {col2}\\nwithin {col1}\", y=0.5)\n",
        "    # plt.legend(mypie, group_names, loc=\"best\")\n",
        "\n",
        "    plt.margins(0, 0)\n",
        "    plt.show()\n",
        "\n",
        "    print(np.sort(df[col2].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def corr_city_month(df:pd.DataFrame, col:str):\n",
        "    \"\"\"\n",
        "    it groups by month and city, then it computes corr in the corresponding variable col\n",
        "    \"\"\"\n",
        "\n",
        "    dfg = df.groupby([\"city\",'month'])[[col]].sum()\n",
        "    dfg = dfg.reset_index()\n",
        "    dfg.head(2)\n",
        "\n",
        "    grouped_df = dfg.groupby('city')\n",
        "\n",
        "    matrix_df = pd.DataFrame(index=grouped_df.groups.keys(), columns=grouped_df.groups.keys())\n",
        "    for group1_name, group1_data in grouped_df:\n",
        "        for group2_name, group2_data in grouped_df:\n",
        "            if group1_name != group2_name:\n",
        "                correlation = stats.pearsonr(group1_data[col], group2_data[col])[0]\n",
        "                matrix_df.loc[group1_name, group2_name] = correlation\n",
        "\n",
        "    return matrix_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_hist_3d(data:pd.DataFrame, x:str, y:str, log_scale:bool=False):\n",
        "    \"\"\"\n",
        "    it plots a 3d histogram in a 2d plane. \n",
        "    - One histogram will be computed per group in \"x\".\n",
        "    - That histogram will show the frequencies for values in \"y\". \n",
        "    - The corresponding freq value will be represented by a color\n",
        "    @param log_scale: True if you want that the y-values are scaled by the log function\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(20,3))\n",
        "    ax = sns.histplot(data=data,x=x,y=y, log_scale=log_scale, cmap='flare')\n",
        "    plt.colorbar(ax.collections[0], label=y)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load input data\n",
        "workfolder = r'.\\..'  # root folder\n",
        "pathfile = os.path.join(workfolder,r'Data\\bank_transactions.parquet')\n",
        "df = pd.read_parquet(pathfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.account_id.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove \\' to easy data management\n",
        "df['account_id'] = df['account_id'].str.replace(\"'\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# any register should be either withdrawal or deposit\n",
        "s = df.loc[ (df.withdrawal_amt.isna()) & (df.deposit_amt.isna()) ]\n",
        "if len(s):\n",
        "    logging.warning(f'There is {len(s)} regs for review')\n",
        "# i should have any register with values in both columns:\n",
        "if (len(df) - (df.withdrawal_amt.isna().sum() + df.deposit_amt.isna().sum()))!=0:\n",
        "    logging.warning('There are registers with values in both columns: withdrawal and deposit')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "lets create some useful columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# year of transaction\n",
        "df['month'] = df['date'].apply(lambda x: x.replace(day=1))\n",
        "# month of transaction\n",
        "df['year'] = df['date'].apply(lambda x: x.replace(month=1, day=1))\n",
        "# difference in days between end and start transaction\n",
        "df['date_diff'] = (df.value_date - df.date).dt.days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.date_diff>0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have:\n",
        "- a total of 116,201 transactions\n",
        "- data from 10 accounts\n",
        "- transactions from 2015-01-01 to 2019-03-05, i.e. 4y + 2m +4d\n",
        "- 44,806 different transaction details\n",
        "- 905 (0.78%) transaction were made using check\n",
        "- 18 categories:\n",
        "    - 'Transfer', 'Investment', 'Miscellaneous', 'Loan Payment',\n",
        "    - 'Subscriptions', 'Pets & Pet Care', 'Food & Dining',\n",
        "    - 'Utility Bill', 'Electronics & Gadgets', 'Insurance', 'Travel',\n",
        "    - 'Shopping', 'Education', 'Health & Wellness',\n",
        "    - 'Charity & Donations', 'Entertainment', 'Transportation',\n",
        "    - 'Childcare & Parenting'\n",
        "- 10 source cities (all in USA): \n",
        "    - 'New York',       'Phoenix',   'Dallas',  'San Jose',     'Philadelphia', \n",
        "    - 'San Antonio',    'San Diego', 'Houston', 'Los Angeles',  'Chicago'\n",
        "- 3 device types: 'Tablet', 'Mobile', 'Desktop'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See data distribution:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that city and device have very nice distributions, i.e. almost equal data distribution per category:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,3))\n",
        "plt.subplot(121)\n",
        "pie(df,'city')\n",
        "\n",
        "plt.subplot(122)\n",
        "pie(df,'device')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "lets see device usage inside each city:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_pies(df,col1='city',col2='device')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "lets see the category per city in the whole time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_pies(df,col1='city',col2='category',len2=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# withdrawals\n",
        "two_pies(df[~df.withdrawal_amt.isna() ],col1='city',col2='category',len2=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = df[ ~(df.withdrawal_amt.isna()) ]\n",
        "s = s.groupby('city').category.value_counts().reset_index().sort_values(by=['city','count'])\n",
        "s\n",
        "s.groupby('city').nth(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hasta aquí tío lafa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[(df.city=='San Jose') & (df.category=='Transfer') & (~df.withdrawal_amt.isna())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# deposits\n",
        "two_pies(df[(~df.deposit_amt.isna()) ],col1='city',col2='category',len2=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "lets compare the first year 2015 vs the year 2018 ( i do not use year 2019 beacuase it does not have data from all the months)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2015: city and device\n",
        "two_pies(df[df.year=='2015-01-01'],col1='city',col2='device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2018: city and device\n",
        "two_pies(df[df.year=='2018-01-01'],col1='city',col2='device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2015: city and category\n",
        "two_pies(df[df.year=='2015-01-01'],col1='city',col2='category',len2=6)\n",
        "print(df.category.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2018: city and category\n",
        "two_pies(df[df.year=='2018-01-01'],col1='city',col2='category',len2=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2015: city and category only for withdrawal\n",
        "two_pies(df[(df.year=='2015-01-01') & (~df.withdrawal_amt.isna()) ],col1='city',col2='category',len2=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2015: city and category only for deposits\n",
        "two_pies(df[(df.year=='2015-01-01') & (~df.deposit_amt.isna()) ],col1='city',col2='category',len2=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets see withdrawals and deposits:\n",
        "- the tendency (using median) is that transactions for deposits (426,500) are higher than withdrawals (47,083)\n",
        "    - Thus, one may have the first impression that the market will distribute the cash in the amts and we just need to pay attetion to collect the money from amts, not placing it. We could have a further analysis\n",
        "- distributions seems to be bimodal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# withdrawal_amt\n",
        "s = df.loc[~df.withdrawal_amt.isna(), 'withdrawal_amt']\n",
        "sns.histplot(data=s, bins=50, kde=True, alpha=1, log_scale=True, label='withdrawal_amt')\n",
        "\n",
        "# deposit_amt\n",
        "s = df.loc[~df.deposit_amt.isna(), 'deposit_amt']\n",
        "sns.histplot(data=s, bins=50, kde=True, alpha=0.3, log_scale=True, label='deposit')\n",
        "\n",
        "# median values\n",
        "s = df.loc[:,['withdrawal_amt','deposit_amt']].median()\n",
        "sns.lineplot(x=[s.loc['withdrawal_amt'],s.loc['withdrawal_amt']], y=[0,7500], color='blue', label='median_wd')\n",
        "sns.lineplot(x=[s.loc['deposit_amt'],s.loc['deposit_amt']], y=[0,7500], color='orange', label='median_dp')\n",
        "\n",
        "plt.legend(); plt.plot(); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[:,['withdrawal_amt','deposit_amt']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "some extra questions from this data:\n",
        "- transctions by city\n",
        "- transactions by device\n",
        "    - what device is associated to the highest transaction values?\n",
        "    --> all transaction are digitally made, there is no \n",
        "- transactions with bank checks, with value range manage?\n",
        "- transactions by months, any yearly tendency?\n",
        "- is there any category value related to the value?\n",
        "- how should i distribute the cash in the city? (depending on the relation deposits vs withdrawals)\n",
        "    - -> nope, i am only managing digital transaction, all transaction have a digital device associated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observed that all cities manage similar withdrawal transferences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,3))\n",
        "ax = sns.histplot(data=df,x='city',y='withdrawal_amt', log_scale=True, cmap='flare')\n",
        "plt.colorbar(ax.collections[0], label='withdrawal_amt')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observed that all devices manage similar withdrawal transferences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,3))\n",
        "ax = sns.histplot(data=df,x='device',y='withdrawal_amt', log_scale=True, cmap='flare')\n",
        "plt.colorbar(ax.collections[0], label='withdrawal_amt')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observed accounts DO NOT manage similar withdrawal transferences, nor deposit transferences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# withdrawal\n",
        "plot_hist_3d(data=df,x='account_id',y='withdrawal_amt', log_scale=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# deposit\n",
        "plot_hist_3d(data=df,x='account_id',y='deposit_amt', log_scale=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# balance\n",
        "plot_hist_3d(data=df,x='account_id',y='balance_amt', log_scale=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# withdrawals\n",
        "plot_hist_3d(data=df[~df.withdrawal_amt.isna()],x='account_id',y='category', log_scale=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# deposits\n",
        "plot_hist_3d(data=df[~df.deposit_amt.isna()], x='account_id', y='category', log_scale=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cities. only withdrawals\n",
        "plot_hist_3d(data=df[~df.withdrawal_amt.isna()], x='account_id', y='city', log_scale=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cities. only deposit\n",
        "plot_hist_3d(data=df[~df.deposit_amt.isna()], x='account_id', y='city', log_scale=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bank checks analysis:\n",
        "- Checks are used only for withdrawals, no one for deposit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.loc[~df.chq_no.isna(), 'deposit_amt'].describe())\n",
        "print(df.loc[~df.chq_no.isna(), 'withdrawal_amt'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(3,3))\n",
        "sns.histplot(df.loc[~df.chq_no.isna(), 'withdrawal_amt'], log_scale=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## by months:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sort_values(by='date')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- general by month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = df.groupby('month')[['withdrawal_amt','deposit_amt']].sum().reset_index()\n",
        "sns.lineplot(s,x='month',y='withdrawal_amt', label='withdrawal_amt')\n",
        "sns.lineplot(s,x='month',y='deposit_amt', label='deposit_amt')\n",
        "plt.legend(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- by month and city:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = df.groupby(['city','month'])[['withdrawal_amt','deposit_amt']].sum().reset_index()\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(121)\n",
        "sns.lineplot(data=s,x='month',y='withdrawal_amt', hue='city')\n",
        "plt.title('withdrawal_amt')\n",
        "\n",
        "plt.subplot(122)\n",
        "sns.lineplot(data=s,x='month',y='deposit_amt', hue='city')\n",
        "plt.title('deposit_amt')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lets see correlation between information per city"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# group per city and month, and compute correlation for withdrawals\n",
        "s = corr_city_month(df, col='withdrawal_amt')\n",
        "display(s)\n",
        "print(s.min().min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = corr_city_month(df, col='deposit_amt')\n",
        "display(s)\n",
        "print(s.min().min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Per city, data series are very similar. All have a corr>84% for withdrawals and deposits\n",
        "\n",
        "Thus, lets analyze the accounts "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we can see that the bank balance is always negative and it is in average decreasing at a speed of\n",
        "-23,865,986,426 per month!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear_tendency(s,col:str):\n",
        "    \"\"\"it computes linear tendency to series input over the column col\"\"\"\n",
        "    x = np.arange(s.shape[0])\n",
        "    linear_fit = np.polyfit(x, s[col], 1)\n",
        "    linear_trend = np.poly1d(linear_fit)\n",
        "    return linear_fit, linear_trend(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# group balance by month\n",
        "s = df.groupby('month').balance_amt.sum()\n",
        "s = s.reset_index()\n",
        "print(s.balance_amt.describe())\n",
        "\n",
        "# plot behaviour\n",
        "sns.lineplot(data=s,x=s.month,y=s.balance_amt, marker='o')\n",
        "\n",
        "# see the linear tendency of general balance\n",
        "linear_fit, linear_trend = linear_tendency(s,'balance_amt')\n",
        "plt.plot(s.month.to_list(), linear_trend, linestyle='--', color='red')\n",
        "\n",
        "plt.title('Balance per month')\n",
        "plt.show()\n",
        "\n",
        "# print the slope, \n",
        "print('Slope: ', linear_fit[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- balance per city\n",
        "\n",
        "behaviour in all cities have the same behaviour, debts from users to bank have a strong increasement in july 2015 and decreases in march 2019, where the general balance returns to similar values as at the beggining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# group balance by city and month\n",
        "s = df.groupby(['city', 'year','month']).balance_amt.sum()\n",
        "s = s.reset_index()\n",
        "s\n",
        "# # plot behaviour\n",
        "for y in s.year.unique():\n",
        "    sy = s.loc[s.year==y,['city','month','balance_amt']]\n",
        "    plt.figure(figsize=(12,3))\n",
        "    sns.barplot(data=sy, x='month', y='balance_amt', hue='city')\n",
        "    plt.title(f'Balance per month. Year {y}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "lets compare the first three months from 2015 and 2019:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = df[(df.month<='2015-06-01') | (df.month>='2019-01-01')]\n",
        "plt.figure(figsize=(12,3))\n",
        "sns.barplot(data=s, x='month', y='balance_amt', hue='city')\n",
        "plt.title(f'Balance per month. Year {y}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## lest see one account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.groupby('account_id').date.count().sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "lets work with the accout 1196428 due to it has more data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- balance per account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfq = df[df.account_id=='409000493201'].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# group balance by city and month\n",
        "s = dfq.groupby(['city', 'year','month']).balance_amt.sum()\n",
        "s = s.reset_index()\n",
        "s\n",
        "# # plot behaviour\n",
        "for y in s.year.unique():\n",
        "    sy = s.loc[s.year==y,['city','month','balance_amt']]\n",
        "    plt.figure(figsize=(12,3))\n",
        "    sns.barplot(data=sy, x='month', y='balance_amt', hue='city')\n",
        "    plt.title(f'Balance per month. Year {y}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# withdrawal transactions\n",
        "two_pies(dfq[(dfq.year=='2016-01-01') & (~dfq.withdrawal_amt.isna()) ],col1='city',col2='category',len2=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# desposit transactions\n",
        "two_pies(dfq[(dfq.year=='2018-01-01') & (~dfq.deposit_amt.isna()) ],col1='city',col2='category',len2=6)"
      ]
    }
  ],
  "metadata": {
    "@webio": {
      "lastCommId": "814db409262d41e59a8f535448fcae85",
      "lastKernelId": "3183b2f9-976f-49e9-9ea7-931bafbad9e4"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
